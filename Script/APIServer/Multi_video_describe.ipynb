{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-17T05:06:09.091851Z",
     "start_time": "2025-06-17T05:06:02.264081Z"
    }
   },
   "source": [
    "import os\n",
    "# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7897'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7897'\n",
    "\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part, Content, Image\n",
    "from google.cloud import aiplatform\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "import vertexai\n",
    "import base64\n",
    "import logging\n",
    "import colorlog\n",
    "\n",
    "\n",
    "\n",
    "def init_logging():\n",
    "    # 配置日志\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s %(message)s',\n",
    "        handlers=[\n",
    "            # 把日志同时输出到文件和控制台\n",
    "            logging.FileHandler('./video_describe.txt', mode='w', encoding='utf-8'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 创建一个控制台处理器，并使用 colorlog 格式化\n",
    "    console_handler = logging.StreamHandler()\n",
    "    formatter = colorlog.ColoredFormatter(\n",
    "        '%(log_color)s%(asctime)s %(message)s',\n",
    "        log_colors={\n",
    "            'DEBUG': 'cyan',\n",
    "            'INFO': 'green',\n",
    "            'WARNING': 'yellow',\n",
    "            'ERROR': 'red',\n",
    "            'CRITICAL': 'red,bg_white',\n",
    "        }\n",
    "    )\n",
    "    console_handler.setFormatter(formatter)\n",
    "\n",
    "    # 获取日志记录器\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.addHandler(console_handler)\n",
    "    return logger\n",
    "\n",
    "\n",
    "logger = init_logging()\n",
    "MODEL_DICT = {'gemini-2.0': 'gemini-2.0-flash-001', 'gemini-2.0-lite': 'gemini-2.0-flash-lite-001',\n",
    "              'gemini-embedding': 'gemini-embedding-001', 'text_embedding': 'text-embedding-005',\n",
    "              'text-multilingual-embedding': 'text-multilingual-embedding-002', 'multimodalembedding': 'multimodalembedding@001'}\n",
    "\n",
    "\n",
    "def init_valid(vertex_client_json_path=r'E:\\Data\\datasets\\Video_Datasets\\Koala-36M\\Code\\APIServer\\vertex_client.json',\n",
    "               port=9002,\n",
    "               project=None,\n",
    "               token_json=None):\n",
    "    \"\"\"验证用户\"\"\"\n",
    "\n",
    "    scopes = ['https://www.googleapis.com/auth/cloud-platform']\n",
    "    if token_json is not None and os.path.exists(token_json):\n",
    "        # TODO: 根据token验证\n",
    "        creds = Credentials.from_authorized_user_file(token_json, scopes=scopes)\n",
    "    else:\n",
    "        # 加载OAuth 2.0 凭证\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            vertex_client_json_path, scopes=scopes\n",
    "        )\n",
    "        creds = flow.run_local_server(port=port)\n",
    "    aiplatform.init(credentials=creds, project=project)\n",
    "\n",
    "\n",
    "\n",
    "def video2part(video_path):\n",
    "    \"\"\"视频转为模型输入\"\"\"\n",
    "    with open(video_path, 'rb') as f:\n",
    "        video_bytes = f.read()\n",
    "    video_base64 = base64.b64encode(video_bytes).decode('utf-8')\n",
    "    video_part = Part.from_data(data=video_base64, mime_type='video/mp4')\n",
    "    return video_part\n",
    "\n",
    "\n",
    "def load_local_data(content_lst):\n",
    "    \"\"\"加载数据\"\"\"\n",
    "    res_content_lst = []\n",
    "    if isinstance(content_lst, str):\n",
    "        content_lst = [content_lst]\n",
    "    for content in content_lst:\n",
    "        try:\n",
    "            if os.path.exists(content):\n",
    "                # 图像\n",
    "                if os.path.basename(content).split('.')[-1] in ['jpg', 'png', 'jpeg']:\n",
    "                    image = Image.load_from_file(content)\n",
    "                    res_content_lst.append(image)\n",
    "                    logger.debug(f'图像:{content}')\n",
    "                # 视频\n",
    "                elif os.path.basename(content).split('.')[-1] in ['mp4']:\n",
    "                    video = video2part(content)\n",
    "                    res_content_lst.append(video)\n",
    "                    logger.debug(f'视频:{content}')\n",
    "                else:\n",
    "                    raise ValueError(f'输入路径文件错误: {content}')\n",
    "            # 文本\n",
    "            else:\n",
    "                res_content_lst.append(content)\n",
    "                logger.debug(f'文本: {content}')\n",
    "        except Exception as e:\n",
    "            logger.error(f'load local file error: {e}')\n",
    "    return res_content_lst\n",
    "\n",
    "\n",
    "\n",
    "model_name = MODEL_DICT['gemini-2.0-lite']\n",
    "\n",
    "# 用户验证\n",
    "init_valid(vertex_client_json_path='./vertex_client.json', port=9002, project='video-describe')\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=127057636192-venn5l6jmo6mj0bc34lp75fpkn5f75o4.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A9002%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform&state=gOs4PK89WPsbgHcnGI6b5xXabFeOgg&access_type=offline\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 多轮对话",
   "id": "c3dfe644ef6a25c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:06:13.914880Z",
     "start_time": "2025-06-17T05:06:13.885981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "answering_style_message = \"\"\"**Answering Style**:\n",
    "Answers should be comprehensive, conversational, and use complete sentences. The answer should be in English no matter what the user‘s input is. Provide context where necessary and maintain a certain tone.  Begin directly without introductory phrases like “The image/video showcases” “The photo/video captures” “In the first/second video” and more. For example, say “A woman is on a beach”, instead of “A woman is depicted in the image”. Cannot appear as vague expressions. Please note that there should be no expressions such as video1 or video2 when describing.\"\"\"\n",
    "note_message = \"\"\"**Note**:\n",
    " When describing, first describe the character and scene, then describe the events that occurred in the video, as well as the actions of the characters.\"\"\"\n",
    "user_input_message = \"\"\"**User Input**:\n",
    "Please detailed describe each video in order and express the same elements in different videos in the same way. When describing the characters, it is necessary to give actor1, actor2, etc. and describe who actor1 and actor2 are\"\"\"\n",
    "output_format = \"\"\"\n",
    "output_format:\n",
    " [the first video description]\n",
    " [the first video description]\n",
    " [the first video description]\n",
    "\"\"\"\n",
    "system_message = f\"{answering_style_message}\\n{note_message}\\n{output_format}\\n{user_input_message}\"\n",
    "\n",
    "\n",
    "# 加载模型\n",
    "logger.info(f'加载模型中: {model_name}...')\n",
    "model = GenerativeModel(model_name, system_instruction=system_message)\n",
    "logger.info('加载模型成功!!!')\n",
    "logger.info('***\\t\\t system_instruction \\t\\t***: \\n' + system_message)\n",
    "\n",
    "chat = model.start_chat()"
   ],
   "id": "104bae6c8dbb6b7b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-06-17 13:06:13,892 加载模型中: gemini-2.0-flash-lite-001...\u001B[0m\n",
      "\u001B[32m2025-06-17 13:06:13,894 加载模型成功!!!\u001B[0m\n",
      "\u001B[32m2025-06-17 13:06:13,895 ***\t\t system_instruction \t\t***: \n",
      "**Answering Style**:\n",
      "Answers should be comprehensive, conversational, and use complete sentences. The answer should be in English no matter what the user‘s input is. Provide context where necessary and maintain a certain tone.  Begin directly without introductory phrases like “The image/video showcases” “The photo/video captures” “In the first/second video” and more. For example, say “A woman is on a beach”, instead of “A woman is depicted in the image”. Cannot appear as vague expressions. Please note that there should be no expressions such as video1 or video2 when describing.\n",
      "**Note**:\n",
      " When describing, first describe the character and scene, then describe the events that occurred in the video, as well as the actions of the characters.\n",
      "\n",
      "output_format:\n",
      " [the first video description]\n",
      " [the first video description]\n",
      " [the first video description]\n",
      "\n",
      "**User Input**:\n",
      "Please detailed describe each video in order and express the same elements in different videos in the same way. When describing the characters, it is necessary to give actor1, actor2, etc. and describe who actor1 and actor2 are\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:13:48.550320Z",
     "start_time": "2025-06-17T05:12:32.214425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content_lst = [\n",
    "               r\"E:\\Data\\datasets\\Video_Datasets\\Koala-36M\\videos\\0-ggn3z52oU_76\\split\\The Silent Pocket 20 Liter Faraday Pack A Quick Shabazz Review-Scene-002.mp4\",\n",
    "                r\"E:\\Data\\datasets\\Video_Datasets\\Koala-36M\\videos\\0-ggn3z52oU_76\\split\\The Silent Pocket 20 Liter Faraday Pack A Quick Shabazz Review-Scene-004.mp4\"\n",
    "               ]\n",
    "\n",
    "# 从本地加载数据\n",
    "logger.info('加载数据中...')\n",
    "model_input_content_lst = load_local_data(content_lst)\n",
    "logger.info('加载完成')\n",
    "\n",
    "# 模型预测\n",
    "logger.info('模型预测中...')\n",
    "response1 = chat.send_message(content=['请描述视频', model_input_content_lst[0]])\n",
    "logger.info(f'\\n\\n{response1.text}')\n",
    "response2 = chat.send_message(content=['请描述视频', model_input_content_lst[1]])\n",
    "logger.info(f'\\n\\n{response2.text}')\n",
    "\n"
   ],
   "id": "27550cc59ff87f3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-06-17 13:12:32,248 加载数据中...\u001B[0m\n",
      "\u001B[32m2025-06-17 13:12:32,280 加载完成\u001B[0m\n",
      "\u001B[32m2025-06-17 13:12:32,287 模型预测中...\u001B[0m\n",
      "\u001B[32m2025-06-17 13:13:09,165 \n",
      "\n",
      "Sure, here is a detailed description of the video you requested.\n",
      "\n",
      "The video begins with a shot of a black bag laying on a tan carpet. The bag is a silent pocket 20 liter pack. Actor 1, who is off camera, starts to unzip the bag and opens it up to reveal the inside. As Actor 1 continues to open the bag it becomes more apparent that it is a waterproof bag. Finally, Actor 1 zooms in and begins to show the details of the outside of the bag.\u001B[0m\n",
      "\u001B[32m2025-06-17 13:13:48,535 \n",
      "\n",
      "Here is a detailed description of the video you requested.\n",
      "\n",
      "The video starts with a black bag laying flat on the floor, with the side facing the camera. The bag has a zipper pocket in the middle of the bag. The bag is a silent pocket 20 liter pack. Actor 1, who is off camera, pulls a zipper up the pocket.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "16c3366ebf7a24e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
